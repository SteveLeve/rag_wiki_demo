{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b2e83b",
   "metadata": {},
   "source": [
    "## Load-or-Generate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_generate(db_connection, embedding_model: str, embedding_alias: str,\n",
    "                     dataset: list = None, target_size_mb: int = None,\n",
    "                     max_chunk_size: int = 1000,\n",
    "                     chunk_source_dataset: str = None,\n",
    "                     preserve_existing: Optional[bool] = None,\n",
    "                     embedding_generation_func = None) -> 'PostgreSQLVectorDB':\n",
    "    \"\"\"Smart loader: check registry, load if exists and compatible, generate if not.\n",
    "    \n",
    "    This pattern enables advanced notebooks to work flexibly:\n",
    "    - If embeddings exist in DB → load immediately (no regeneration)\n",
    "    - If not in DB but dataset available → optionally generate\n",
    "    - Check metadata for compatibility (dimension, chunk config, etc.)\n",
    "    \n",
    "    Args:\n",
    "        db_connection: PostgreSQL connection\n",
    "        embedding_model: Model identifier (e.g., 'hf.co/CompendiumLabs/bge-base-en-v1.5-gguf')\n",
    "        embedding_alias: Short alias for registry (e.g., 'bge_base_en_v1_5')\n",
    "        dataset: List of text chunks (optional, only needed for generation)\n",
    "        target_size_mb: Dataset size goal (optional)\n",
    "        max_chunk_size: Maximum chunk size in characters\n",
    "        chunk_source_dataset: Description of the data source\n",
    "        preserve_existing: If True, always load; if False, always regenerate;\n",
    "                          if None, prompt user interactively\n",
    "        embedding_generation_func: Function to call if generation needed.\n",
    "                                   Should accept (dataset, embedding_model, embedding_alias, db)\n",
    "                                   and populate the embeddings table\n",
    "    \n",
    "    Returns:\n",
    "        PostgreSQLVectorDB instance ready for use\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If embeddings don't exist and no generation function provided\n",
    "    \"\"\"\n",
    "    # First, check if embeddings exist in registry\n",
    "    with db_connection.cursor() as cur:\n",
    "        cur.execute('''\n",
    "            SELECT id, dimension, embedding_count, metadata_json\n",
    "            FROM embedding_registry\n",
    "            WHERE model_alias = %s\n",
    "        ''', (embedding_alias,))\n",
    "        registry_entry = cur.fetchone()\n",
    "    \n",
    "    if registry_entry:\n",
    "        reg_id, dimension, embedding_count, metadata = registry_entry\n",
    "        \n",
    "        print(f\"\\n✓ Found {embedding_count} existing embeddings for '{embedding_alias}'\")\n",
    "        print(f\"  Dimension: {dimension}\")\n",
    "        print(f\"  Created: {metadata.get('created_at', 'unknown') if metadata else 'unknown'}\")\n",
    "        \n",
    "        # Determine whether to load or regenerate\n",
    "        should_load = True\n",
    "        \n",
    "        if preserve_existing is False:\n",
    "            should_load = False\n",
    "            print(f\"\\n⚠️  Will regenerate embeddings (preserve_existing=False)\")\n",
    "        elif preserve_existing is None:\n",
    "            # Interactive prompt\n",
    "            while True:\n",
    "                response = input(f\"\\nLoad existing embeddings? [(l)oad / (r)egenerate / (c)ancel]: \").lower().strip()\n",
    "                if response in ['l', 'load']:\n",
    "                    should_load = True\n",
    "                    break\n",
    "                elif response in ['r', 'regenerate']:\n",
    "                    should_load = False\n",
    "                    break\n",
    "                elif response in ['c', 'cancel']:\n",
    "                    raise ValueError(\"User cancelled operation\")\n",
    "        \n",
    "        if should_load:\n",
    "            # Load from PostgreSQL\n",
    "            table_name = f'embeddings_{embedding_alias.replace(\".\", \"_\")}'\n",
    "            return PostgreSQLVectorDB(\n",
    "                db_connection.get_dsn_parameters(),\n",
    "                table_name,\n",
    "                preserve_existing=True  # Already exists\n",
    "            )\n",
    "    \n",
    "    # If we reach here, either no embeddings exist or user chose to regenerate\n",
    "    if not embedding_generation_func:\n",
    "        raise ValueError(\n",
    "            f\"No existing embeddings for '{embedding_alias}' and \"\n",
    "            \"no generation function provided. \"\n",
    "            \"Pass embedding_generation_func parameter.\"\n",
    "        )\n",
    "    \n",
    "    if not dataset:\n",
    "        raise ValueError(\n",
    "            f\"Dataset required for generating embeddings. \"\n",
    "            \"Pass the dataset parameter.\"\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nGenerating new embeddings for '{embedding_alias}'...\")\n",
    "    print(f\"Dataset: {len(dataset)} chunks\")\n",
    "    \n",
    "    # Call the generation function\n",
    "    return embedding_generation_func(\n",
    "        dataset=dataset,\n",
    "        embedding_model=embedding_model,\n",
    "        embedding_alias=embedding_alias,\n",
    "        db=db_connection,\n",
    "        max_chunk_size=max_chunk_size,\n",
    "        chunk_source_dataset=chunk_source_dataset\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fa5f5",
   "metadata": {},
   "source": [
    "## Usage Example in Advanced Notebook\n",
    "\n",
    "```python\n",
    "# At top of your advanced technique notebook:\n",
    "\n",
    "from foundation.00_registry_and_tracking_utilities import (\n",
    "    list_available_embeddings,\n",
    "    load_or_generate\n",
    ")\n",
    "\n",
    "# Show available embeddings\n",
    "available = list_available_embeddings(db)\n",
    "print(available)\n",
    "\n",
    "# Define your embedding generation function\n",
    "def generate_embeddings(dataset, embedding_model, embedding_alias, db, \n",
    "                        max_chunk_size, chunk_source_dataset):\n",
    "    \"\"\"Your existing embedding generation logic.\"\"\"\n",
    "    # ... implementation ...\n",
    "    register_embedding(db, embedding_alias, ...)  # Register after generating\n",
    "    return PostgreSQLVectorDB(...)  # Return DB instance\n",
    "\n",
    "# Use load_or_generate for flexibility\n",
    "db = load_or_generate(\n",
    "    db_connection=db,\n",
    "    embedding_model=EMBEDDING_MODEL,\n",
    "    embedding_alias=EMBEDDING_MODEL_ALIAS,\n",
    "    dataset=dataset if regenerate else None,  # Only pass if regenerating\n",
    "    chunk_source_dataset=f'Wikipedia {TARGET_SIZE_MB}MB',\n",
    "    preserve_existing=True,  # Reuse if exists\n",
    "    embedding_generation_func=generate_embeddings\n",
    ")\n",
    "\n",
    "# Now db is ready, with minimal overhead if embeddings already exist\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
