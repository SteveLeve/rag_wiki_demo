{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeacd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c462713",
   "metadata": {},
   "source": [
    "## Registry Discovery Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_available_embeddings(db_connection) -> pd.DataFrame:\n",
    "    \"\"\"Query embedding_registry to show available models with metadata.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: model_alias, model_name, dimension, embedding_count, \n",
    "                                 chunk_source_dataset, created_at, chunk_size_config\n",
    "    \"\"\"\n",
    "    query = '''\n",
    "        SELECT \n",
    "            model_alias,\n",
    "            model_name,\n",
    "            dimension,\n",
    "            embedding_count,\n",
    "            chunk_source_dataset,\n",
    "            chunk_size_config,\n",
    "            created_at,\n",
    "            last_accessed\n",
    "        FROM embedding_registry\n",
    "        ORDER BY created_at DESC\n",
    "    '''\n",
    "    return pd.read_sql(query, db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_metadata(db_connection, model_alias: str) -> Optional[Dict]:\n",
    "    \"\"\"Fetch metadata_json and other info for a specific model.\n",
    "    \n",
    "    Args:\n",
    "        db_connection: PostgreSQL connection\n",
    "        model_alias: The model alias (e.g., 'bge_base_en_v1_5')\n",
    "        \n",
    "    Returns:\n",
    "        Dict with: dimension, embedding_count, config_hash (if stored),\n",
    "                   chunk_source_dataset, created_at, metadata_json\n",
    "    \"\"\"\n",
    "    with db_connection.cursor() as cur:\n",
    "        cur.execute('''\n",
    "            SELECT \n",
    "                dimension,\n",
    "                embedding_count,\n",
    "                chunk_source_dataset,\n",
    "                chunk_size_config,\n",
    "                created_at,\n",
    "                metadata_json\n",
    "            FROM embedding_registry\n",
    "            WHERE model_alias = %s\n",
    "        ''', (model_alias,))\n",
    "        result = cur.fetchone()\n",
    "        \n",
    "        if not result:\n",
    "            return None\n",
    "        \n",
    "        return {\n",
    "            'dimension': result[0],\n",
    "            'embedding_count': result[1],\n",
    "            'chunk_source_dataset': result[2],\n",
    "            'chunk_size_config': result[3],\n",
    "            'created_at': result[4],\n",
    "            'metadata_json': result[5] or {}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_embedding(db_connection, model_alias: str, model_name: str, \n",
    "                       dimension: int, embedding_count: int, \n",
    "                       chunk_source_dataset: str = None,\n",
    "                       chunk_size_config: int = None,\n",
    "                       metadata: Dict = None) -> bool:\n",
    "    \"\"\"Register or update an embedding model in the registry.\n",
    "    \n",
    "    Call this after generating embeddings to enable discovery by other notebooks.\n",
    "    \n",
    "    Args:\n",
    "        db_connection: PostgreSQL connection\n",
    "        model_alias: Identifier for the model (e.g., 'bge_base_en_v1_5')\n",
    "        model_name: Human-readable model name (e.g., 'BGE Base EN v1.5')\n",
    "        dimension: Embedding vector dimension (usually 768)\n",
    "        embedding_count: Number of embeddings stored\n",
    "        chunk_source_dataset: Description of source data\n",
    "        chunk_size_config: MAX_CHUNK_SIZE used during generation\n",
    "        metadata: Optional dict with notes, URLs, training_date, etc.\n",
    "        \n",
    "    Returns:\n",
    "        True if successful\n",
    "    \"\"\"\n",
    "    if metadata is None:\n",
    "        metadata = {}\n",
    "    \n",
    "    try:\n",
    "        with db_connection.cursor() as cur:\n",
    "            # Use INSERT ... ON CONFLICT for upsert behavior\n",
    "            cur.execute('''\n",
    "                INSERT INTO embedding_registry (\n",
    "                    model_alias, model_name, dimension, embedding_count,\n",
    "                    chunk_source_dataset, chunk_size_config, metadata_json\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (model_alias) DO UPDATE SET\n",
    "                    embedding_count = EXCLUDED.embedding_count,\n",
    "                    chunk_source_dataset = COALESCE(EXCLUDED.chunk_source_dataset, embedding_registry.chunk_source_dataset),\n",
    "                    chunk_size_config = COALESCE(EXCLUDED.chunk_size_config, embedding_registry.chunk_size_config),\n",
    "                    metadata_json = EXCLUDED.metadata_json,\n",
    "                    last_accessed = CURRENT_TIMESTAMP\n",
    "            ''', (\n",
    "                model_alias, model_name, dimension, embedding_count,\n",
    "                chunk_source_dataset, chunk_size_config, json.dumps(metadata)\n",
    "            ))\n",
    "        db_connection.commit()\n",
    "        print(f\"✓ Registered embedding: {model_alias} ({embedding_count} chunks)\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to register embedding: {e}\")\n",
    "        db_connection.rollback()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c719c23",
   "metadata": {},
   "source": [
    "## Experiment Tracking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc1d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_config_hash(config_dict: Dict) -> str:\n",
    "    \"\"\"Create deterministic SHA256 hash of a configuration dictionary.\n",
    "    \n",
    "    This enables finding all experiments with identical configurations.\n",
    "    \n",
    "    Args:\n",
    "        config_dict: Configuration parameters\n",
    "        \n",
    "    Returns:\n",
    "        SHA256 hash string (first 12 characters for readability)\n",
    "    \"\"\"\n",
    "    config_str = json.dumps(config_dict, sort_keys=True)\n",
    "    hash_obj = hashlib.sha256(config_str.encode())\n",
    "    return hash_obj.hexdigest()[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_experiment(db_connection, experiment_name: str, \n",
    "                     notebook_path: str = None,\n",
    "                     embedding_model_alias: str = None,\n",
    "                     config: Dict = None,\n",
    "                     techniques: List[str] = None,\n",
    "                     notes: str = None) -> int:\n",
    "    \"\"\"Start a new experiment and return its ID for tracking.\n",
    "    \n",
    "    Args:\n",
    "        db_connection: PostgreSQL connection\n",
    "        experiment_name: Human-readable experiment name\n",
    "        notebook_path: Path to the notebook running this experiment\n",
    "        embedding_model_alias: Which embedding model is being used\n",
    "        config: Dict of configuration parameters\n",
    "        techniques: List of techniques being applied (e.g., ['reranking', 'query_expansion'])\n",
    "        notes: Optional notes about the experiment\n",
    "        \n",
    "    Returns:\n",
    "        Experiment ID for use in save_metrics() and complete_experiment()\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = {}\n",
    "    if techniques is None:\n",
    "        techniques = []\n",
    "    \n",
    "    config_hash = compute_config_hash(config)\n",
    "    \n",
    "    with db_connection.cursor() as cur:\n",
    "        cur.execute('''\n",
    "            INSERT INTO experiments (\n",
    "                experiment_name, notebook_path, embedding_model_alias,\n",
    "                config_hash, config_json, techniques_applied, notes, status\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, 'running')\n",
    "            RETURNING id\n",
    "        ''', (\n",
    "            experiment_name,\n",
    "            notebook_path,\n",
    "            embedding_model_alias,\n",
    "            config_hash,\n",
    "            json.dumps(config),\n",
    "            techniques,\n",
    "            notes\n",
    "        ))\n",
    "        exp_id = cur.fetchone()[0]\n",
    "    db_connection.commit()\n",
    "    print(f\"✓ Started experiment #{exp_id}: {experiment_name}\")\n",
    "    return exp_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_experiment(db_connection, experiment_id: int, \n",
    "                       status: str = 'completed',\n",
    "                       notes: str = None) -> bool:\n",
    "    \"\"\"Mark an experiment as complete.\n",
    "    \n",
    "    Args:\n",
    "        db_connection: PostgreSQL connection\n",
    "        experiment_id: ID returned from start_experiment()\n",
    "        status: 'completed' or 'failed'\n",
    "        notes: Optional update to notes field\n",
    "        \n",
    "    Returns:\n",
    "        True if successful\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with db_connection.cursor() as cur:\n",
    "            update_notes = \", notes = %s\" if notes else \"\"\n",
    "            params = [status, experiment_id] if not notes else [status, notes, experiment_id]\n",
    "            \n",
    "            cur.execute(f'''\n",
    "                UPDATE experiments\n",
    "                SET status = %s{update_notes}, completed_at = CURRENT_TIMESTAMP\n",
    "                WHERE id = %s\n",
    "            ''', params)\n",
    "        db_connection.commit()\n",
    "        print(f\"✓ Experiment #{experiment_id} marked as {status}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to complete experiment: {e}\")\n",
    "        db_connection.rollback()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d55cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(db_connection, experiment_id: int, metrics_dict: Dict,\n",
    "                 export_to_file: bool = True,\n",
    "                 export_dir: str = 'data/experiment_results') -> Tuple[bool, str]:\n",
    "    \"\"\"Save experiment metrics to database and optionally to JSON file.\n",
    "    \n",
    "    Args:\n",
    "        db_connection: PostgreSQL connection\n",
    "        experiment_id: ID from start_experiment()\n",
    "        metrics_dict: Dict of {metric_name: value, ...}\n",
    "                      Can also nest details: {metric_name: {value: X, details: {...}}}\n",
    "        export_to_file: Whether to also save to filesystem JSON\n",
    "        export_dir: Directory for JSON exports\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (success: bool, message: str)\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    try:\n",
    "        with db_connection.cursor() as cur:\n",
    "            for metric_name, metric_data in metrics_dict.items():\n",
    "                # Handle both simple floats and nested dicts with details\n",
    "                if isinstance(metric_data, dict):\n",
    "                    metric_value = metric_data.get('value', 0.0)\n",
    "                    metric_details = metric_data.get('details', {})\n",
    "                else:\n",
    "                    metric_value = metric_data\n",
    "                    metric_details = {}\n",
    "                \n",
    "                cur.execute('''\n",
    "                    INSERT INTO evaluation_results (\n",
    "                        experiment_id, metric_name, metric_value, metric_details_json\n",
    "                    )\n",
    "                    VALUES (%s, %s, %s, %s)\n",
    "                ''', (\n",
    "                    experiment_id,\n",
    "                    metric_name,\n",
    "                    float(metric_value),\n",
    "                    json.dumps(metric_details) if metric_details else '{}'\n",
    "                ))\n",
    "        db_connection.commit()\n",
    "        \n",
    "        # Export to file if requested\n",
    "        file_path = None\n",
    "        if export_to_file:\n",
    "            os.makedirs(export_dir, exist_ok=True)\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            file_path = os.path.join(export_dir, f'experiment_{experiment_id}_{timestamp}.json')\n",
    "            with open(file_path, 'w') as f:\n",
    "                json.dump({\n",
    "                    'experiment_id': experiment_id,\n",
    "                    'timestamp': timestamp,\n",
    "                    'metrics': metrics_dict\n",
    "                }, f, indent=2)\n",
    "        \n",
    "        msg = f\"✓ Saved {len(metrics_dict)} metrics for experiment #{experiment_id}\"\n",
    "        if file_path:\n",
    "            msg += f\" to {file_path}\"\n",
    "        print(msg)\n",
    "        return True, msg\n",
    "    except Exception as e:\n",
    "        msg = f\"✗ Failed to save metrics: {e}\"\n",
    "        print(msg)\n",
    "        db_connection.rollback()\n",
    "        return False, msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27336c8c",
   "metadata": {},
   "source": [
    "## Query & Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4989d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment(db_connection, experiment_id: int) -> Optional[Dict]:\n",
    "    \"\"\"Fetch experiment details and associated metrics.\n",
    "    \n",
    "    Args:\n",
    "        db_connection: PostgreSQL connection\n",
    "        experiment_id: Experiment ID\n",
    "        \n",
    "    Returns:\n",
    "        Dict with experiment info and metrics\n",
    "    \"\"\"\n",
    "    with db_connection.cursor() as cur:\n",
    "        # Get experiment\n",
    "        cur.execute('SELECT * FROM experiments WHERE id = %s', (experiment_id,))\n",
    "        exp = cur.fetchone()\n",
    "        \n",
    "        if not exp:\n",
    "            return None\n",
    "        \n",
    "        # Get metrics for this experiment\n",
    "        cur.execute('''\n",
    "            SELECT metric_name, metric_value, metric_details_json\n",
    "            FROM evaluation_results\n",
    "            WHERE experiment_id = %s\n",
    "            ORDER BY metric_name\n",
    "        ''', (experiment_id,))\n",
    "        metrics = {row[0]: {'value': row[1], 'details': row[2]} for row in cur.fetchall()}\n",
    "        \n",
    "        return {\n",
    "            'id': exp[0],\n",
    "            'name': exp[1],\n",
    "            'notebook': exp[2],\n",
    "            'embedding_model': exp[3],\n",
    "            'config_hash': exp[4],\n",
    "            'config': exp[5],\n",
    "            'techniques': exp[6],\n",
    "            'started_at': exp[7],\n",
    "            'completed_at': exp[8],\n",
    "            'status': exp[9],\n",
    "            'notes': exp[10],\n",
    "            'metrics': metrics\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8943b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_experiments(db_connection, limit: int = 20,\n",
    "                    status: str = None,\n",
    "                    embedding_model: str = None) -> pd.DataFrame:\n",
    "    \"\"\"List recent experiments with optional filtering.\n",
    "    \n",
    "    Args:\n",
    "        db_connection: PostgreSQL connection\n",
    "        limit: Max number of results\n",
    "        status: Filter by status ('running', 'completed', 'failed')\n",
    "        embedding_model: Filter by embedding model alias\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame of experiments\n",
    "    \"\"\"\n",
    "    query = 'SELECT * FROM experiments WHERE 1=1'\n",
    "    params = []\n",
    "    \n",
    "    if status:\n",
    "        query += ' AND status = %s'\n",
    "        params.append(status)\n",
    "    \n",
    "    if embedding_model:\n",
    "        query += ' AND embedding_model_alias = %s'\n",
    "        params.append(embedding_model)\n",
    "    \n",
    "    query += f' ORDER BY started_at DESC LIMIT {limit}'\n",
    "    \n",
    "    return pd.read_sql(query, db_connection, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_experiments(db_connection, experiment_ids: List[int],\n",
    "                       metric_names: List[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"Compare metrics across multiple experiments side-by-side.\n",
    "    \n",
    "    Args:\n",
    "        db_connection: PostgreSQL connection\n",
    "        experiment_ids: List of experiment IDs to compare\n",
    "        metric_names: Specific metrics to compare (if None, all metrics)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with experiments as rows, metrics as columns\n",
    "    \"\"\"\n",
    "    placeholders = ','.join(['%s'] * len(experiment_ids))\n",
    "    \n",
    "    query = f'''\n",
    "        SELECT \n",
    "            e.id,\n",
    "            e.experiment_name,\n",
    "            e.embedding_model_alias,\n",
    "            r.metric_name,\n",
    "            r.metric_value\n",
    "        FROM experiments e\n",
    "        LEFT JOIN evaluation_results r ON e.id = r.experiment_id\n",
    "        WHERE e.id IN ({placeholders})\n",
    "    '''\n",
    "    \n",
    "    if metric_names:\n",
    "        placeholders_metrics = ','.join(['%s'] * len(metric_names))\n",
    "        query += f' AND r.metric_name IN ({placeholders_metrics})'\n",
    "        params = experiment_ids + metric_names\n",
    "    else:\n",
    "        params = experiment_ids\n",
    "    \n",
    "    df = pd.read_sql(query, db_connection, params=params)\n",
    "    # Pivot to get metrics as columns\n",
    "    return df.pivot_table(\n",
    "        index=['id', 'experiment_name', 'embedding_model_alias'],\n",
    "        columns='metric_name',\n",
    "        values='metric_value'\n",
    "    ).reset_index()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
