{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c658eae",
   "metadata": {},
   "source": [
    "# Foundation 00: PostgreSQL Schema Setup\n",
    "\n",
    "**What This Notebook Does:**\n",
    "- Creates the database schema for the entire RAG learning system\n",
    "- **RUN THIS FIRST** before foundation/02, intermediate, advanced, or evaluation notebooks\n",
    "\n",
    "**Expected Runtime:** 1-2 minutes\n",
    "\n",
    "**Prerequisites:**\n",
    "1. PostgreSQL running (via Docker or locally)\n",
    "2. psycopg2-binary installed (`pip install psycopg2-binary`)\n",
    "3. The `pgvector` extension (automatically created when you start the PostgreSQL container)\n",
    "\n",
    "---\n",
    "\n",
    "## The RAG System Architecture\n",
    "\n",
    "This notebook creates 4 core tables that power the entire learning system:\n",
    "\n",
    "| Table | Purpose | Who Uses It |\n",
    "|-------|---------|-----------|\n",
    "| **embedding_registry** | Catalog of embedding models with metadata | foundation/02, intermediate/03-04, advanced/05-10 |\n",
    "| **evaluation_groundtruth** | Human-curated test questions | evaluation-lab/01-04 |\n",
    "| **experiments** | Track each technique/comparison run | All advanced notebooks |\n",
    "| **evaluation_results** | Metrics from each experiment | evaluation-lab/02-04 |\n",
    "\n",
    "**Why this structure?**\n",
    "- **Reuse embeddings**: Don't regenerate (50+ minutes) - just load from registry\n",
    "- **Compare techniques**: Run multiple experiments with same embeddings, different configurations\n",
    "- **Track progress**: See how each technique (reranking, query expansion, etc.) improves metrics\n",
    "- **Share results**: Export experiments and metrics for documentation\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880dca2e",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af3047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL connection\n",
    "POSTGRES_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'rag_db',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ffb480",
   "metadata": {},
   "source": [
    "## Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153639e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=POSTGRES_CONFIG['host'],\n",
    "        port=POSTGRES_CONFIG['port'],\n",
    "        database=POSTGRES_CONFIG['database'],\n",
    "        user=POSTGRES_CONFIG['user'],\n",
    "        password=POSTGRES_CONFIG['password']\n",
    "    )\n",
    "    print(f\"✓ Connected to PostgreSQL at {POSTGRES_CONFIG['host']}:{POSTGRES_CONFIG['port']}\")\n",
    "except psycopg2.OperationalError as e:\n",
    "    print(f\"✗ Failed to connect to PostgreSQL: {e}\")\n",
    "    print(\"Make sure PostgreSQL is running. Start with:\")\n",
    "    print(\"docker run -d --name pgvector-rag \\\\\")\n",
    "    print(\"  -e POSTGRES_PASSWORD=postgres -e POSTGRES_DB=rag_db \\\\\")\n",
    "    print(\"  -p 5432:5432 -v pgvector_data:/var/lib/postgresql/data \\\\\")\n",
    "    print(\"  pgvector/pgvector:pg16\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dfaae9",
   "metadata": {},
   "source": [
    "## Create Schema Tables\n",
    "\n",
    "The following cells create the 4 core tables with proper constraints and metadata storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLE 1: embedding_registry\n",
    "# Purpose: Catalog of embedding models so we can reuse them across notebooks\n",
    "# Used by: foundation/02 (register), intermediate/03 (discover), all advanced techniques (load)\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS embedding_registry (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            model_alias TEXT UNIQUE NOT NULL,        -- Short name like 'bge_base_en_v1_5'\n",
    "            model_name TEXT NOT NULL,                -- Full name like 'hf.co/CompendiumLabs/bge-base-en-v1.5-gguf'\n",
    "            dimension INT NOT NULL,                  -- Vector size (768 for BGE)\n",
    "            embedding_count INT DEFAULT 0,           -- How many chunks embedded\n",
    "            chunk_source_dataset TEXT,               -- Where chunks came from ('Wikipedia 10MB')\n",
    "            chunk_size_config INT,                   -- Max chunk size used (1000 chars)\n",
    "            metadata_json JSONB DEFAULT '{}'::jsonb, -- Flexible: preserve_existing, timestamp, etc.\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    print(\"✓ Created embedding_registry table\")\n",
    "    print(\"  Purpose: Catalog of embedding models for reuse across notebooks\")\n",
    "    print(\"  Example: Store 'bge_base_en_v1_5' with 768 dimensions, 1000+ chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLE 2: evaluation_groundtruth\n",
    "# Purpose: Curated test questions for measuring RAG quality\n",
    "# Used by: evaluation-lab/01 (create/manage), evaluation-lab/02-04 (compute metrics)\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS evaluation_groundtruth (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            question TEXT NOT NULL,                          -- \"What is photosynthesis?\"\n",
    "            source_type TEXT CHECK (source_type IN ('llm_generated', 'template_based', 'manual')),\n",
    "            relevant_chunk_ids INT ARRAY,                   -- Which chunks answer this? [42, 157, 203]\n",
    "            quality_rating TEXT CHECK (quality_rating IN ('good', 'bad', 'ambiguous', 'rejected')),\n",
    "            human_notes TEXT,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            created_by TEXT                                 -- Who created/curated it?\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    print(\"✓ Created evaluation_groundtruth table\")\n",
    "    print(\"  Purpose: Curated test set for measuring retrieval/generation quality\")\n",
    "    print(\"  Example: Store 'What is photosynthesis?' with relevant chunk IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32448df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLE 3: experiments\n",
    "# Purpose: Track each technique/configuration run for reproducibility\n",
    "# Used by: All advanced notebooks (start_experiment), evaluation-lab (compare_experiments)\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS experiments (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            experiment_name TEXT NOT NULL,                  -- \"Reranking with CrossEncoder\"\n",
    "            notebook_path TEXT,                             -- \"advanced-techniques/05-reranking.ipynb\"\n",
    "            embedding_model_alias TEXT,                     -- What embeddings used? 'bge_base_en_v1_5'\n",
    "            config_hash TEXT,                               -- SHA256 hash of exact config (for reproducibility)\n",
    "            config_json JSONB,                              -- Full config: top_n, rerank_threshold, etc.\n",
    "            techniques_applied TEXT ARRAY DEFAULT '{}'::text[],  -- ['reranking', 'hybrid_search']\n",
    "            started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            completed_at TIMESTAMP,\n",
    "            status TEXT DEFAULT 'running' CHECK (status IN ('running', 'completed', 'failed')),\n",
    "            notes TEXT,\n",
    "            FOREIGN KEY (embedding_model_alias) REFERENCES embedding_registry(model_alias)\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    print(\"✓ Created experiments table\")\n",
    "    print(\"  Purpose: Track each technique run with full config for reproducibility\")\n",
    "    print(\"  Example: Store reranking experiment with config_hash to find all similar runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d171621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE TABLE 4: evaluation_results\n",
    "# Purpose: Store metrics from each experiment run\n",
    "# Used by: All advanced notebooks (save_metrics), evaluation-lab/02-04 (query & visualize)\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS evaluation_results (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            experiment_id INT NOT NULL,                     -- Links to experiments table\n",
    "            metric_name TEXT NOT NULL,                      -- 'Precision@5', 'NDCG', 'BLEU'\n",
    "            metric_value FLOAT NOT NULL,                    -- 0.75 (75% precision)\n",
    "            metric_details_json JSONB DEFAULT '{}'::jsonb, -- Flexible: per-query breakdown, etc.\n",
    "            computed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            FOREIGN KEY (experiment_id) REFERENCES experiments(id) ON DELETE CASCADE\n",
    "        )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    print(\"✓ Created evaluation_results table\")\n",
    "    print(\"  Purpose: Store metrics computed for each experiment\")\n",
    "    print(\"  Example: Store Precision@5=0.75 for experiment 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9085059",
   "metadata": {},
   "source": [
    "## Create Indexes for Query Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indexes for common queries\n",
    "indexes = [\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_experiments_embedding_model ON experiments(embedding_model_alias)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_experiments_status ON experiments(status)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_experiments_started ON experiments(started_at DESC)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_results_experiment ON evaluation_results(experiment_id)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_results_metric ON evaluation_results(metric_name)\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_groundtruth_quality ON evaluation_groundtruth(quality_rating)\",\n",
    "]\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    for idx in indexes:\n",
    "        cur.execute(idx)\n",
    "    conn.commit()\n",
    "    print(f\"✓ Created {len(indexes)} indexes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e6e45b",
   "metadata": {},
   "source": [
    "## Verify Schema Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fd9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all tables were created\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute('''\n",
    "        SELECT table_name FROM information_schema.tables \n",
    "        WHERE table_schema = 'public' \n",
    "        AND table_name IN ('embedding_registry', 'evaluation_groundtruth', 'experiments', 'evaluation_results')\n",
    "        ORDER BY table_name\n",
    "    ''')\n",
    "    tables = cur.fetchall()\n",
    "    print(f\"✓ Schema creation complete. Tables found:\")\n",
    "    for (table_name,) in tables:\n",
    "        print(f\"  - {table_name}\")\n",
    "\n",
    "conn.close()\n",
    "print(\"\\n✓ Database connection closed. Ready to proceed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
