{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2250e25",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1bad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import psycopg2\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b682b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ad4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL connection\n",
    "POSTGRES_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'rag_db',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres',\n",
    "}\n",
    "\n",
    "# Test embedding model\n",
    "EMBEDDING_MODEL = 'hf.co/CompendiumLabs/bge-base-en-v1.5-gguf'\n",
    "LANGUAGE_MODEL = 'hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f50c52",
   "metadata": {},
   "source": [
    "## Part 1: Discover Available Embeddings\n",
    "\n",
    "**What's in the registry?** Query the embedding_registry table to see what models and embeddings you have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_available_embeddings(db_connection):\n",
    "    \"\"\"Query embedding_registry to show available models with metadata.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: model_alias, model_name, dimension, embedding_count, etc.\n",
    "    \"\"\"\n",
    "    query = '''\n",
    "        SELECT \n",
    "            model_alias,\n",
    "            model_name,\n",
    "            dimension,\n",
    "            embedding_count,\n",
    "            chunk_source_dataset,\n",
    "            chunk_size_config,\n",
    "            created_at,\n",
    "            last_accessed\n",
    "        FROM embedding_registry\n",
    "        ORDER BY created_at DESC\n",
    "    '''\n",
    "    return pd.read_sql(query, db_connection)\n",
    "\n",
    "# Connect and discover embeddings\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=POSTGRES_CONFIG['host'],\n",
    "        port=POSTGRES_CONFIG['port'],\n",
    "        database=POSTGRES_CONFIG['database'],\n",
    "        user=POSTGRES_CONFIG['user'],\n",
    "        password=POSTGRES_CONFIG['password']\n",
    "    )\n",
    "    print(f'✓ Connected to PostgreSQL')\n",
    "    \n",
    "    # Query registry\n",
    "    available = list_available_embeddings(conn)\n",
    "    \n",
    "    if available.empty:\n",
    "        print(\"\\n⚠️  No embeddings found in registry!\")\n",
    "        print(\"\\nTo populate the registry, run: foundation/02-rag-postgresql-persistent.ipynb\")\n",
    "    else:\n",
    "        print(\"\\n=== Available Embeddings ===\")\n",
    "        print(available.to_string(index=False))\n",
    "        \n",
    "except psycopg2.OperationalError as e:\n",
    "    print(f'✗ Failed to connect: {e}')\n",
    "    print(\"Make sure PostgreSQL is running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1648e1",
   "metadata": {},
   "source": [
    "## Part 2: Load Embeddings from Registry\n",
    "\n",
    "**Now that you know what embeddings exist, load them!** This is instant (no regeneration needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostgreSQLVectorDB:\n",
    "    \"\"\"Helper to load embeddings from PostgreSQL without regeneration.\"\"\"\n",
    "    \n",
    "    def __init__(self, config, table_name):\n",
    "        self.config = config\n",
    "        self.table_name = table_name\n",
    "        self.conn = psycopg2.connect(\n",
    "            host=config['host'],\n",
    "            port=config['port'],\n",
    "            database=config['database'],\n",
    "            user=config['user'],\n",
    "            password=config['password']\n",
    "        )\n",
    "        print(f'✓ Connected to table: {table_name}')\n",
    "    \n",
    "    def get_chunk_count(self):\n",
    "        \"\"\"How many embeddings are stored?\"\"\"\n",
    "        with self.conn.cursor() as cur:\n",
    "            cur.execute(f'SELECT COUNT(*) FROM {self.table_name}')\n",
    "            return cur.fetchone()[0]\n",
    "    \n",
    "    def similarity_search(self, query_embedding, top_n=3):\n",
    "        \"\"\"Retrieve most similar chunks using pgvector.\"\"\"\n",
    "        with self.conn.cursor() as cur:\n",
    "            cur.execute(f'''\n",
    "                SELECT chunk_text, \n",
    "                       1 - (embedding <=> %s::vector) as similarity\n",
    "                FROM {self.table_name}\n",
    "                ORDER BY embedding <=> %s::vector\n",
    "                LIMIT %s\n",
    "            ''', (query_embedding, query_embedding, top_n))\n",
    "            \n",
    "            results = cur.fetchall()\n",
    "            return [(chunk, score) for chunk, score in results]\n",
    "    \n",
    "    def close(self):\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "\n",
    "# Load embeddings from registry (instant - no regeneration)\n",
    "EMBEDDING_MODEL_ALIAS = 'bge_base_en_v1_5'  # Match what foundation/02 registered\n",
    "TABLE_NAME = f'embeddings_{EMBEDDING_MODEL_ALIAS.replace(\".\", \"_\")}'\n",
    "\n",
    "try:\n",
    "    vector_db = PostgreSQLVectorDB(POSTGRES_CONFIG, TABLE_NAME)\n",
    "    count = vector_db.get_chunk_count()\n",
    "    \n",
    "    print(f'\\n✓ Loaded {count:,} embeddings from PostgreSQL (instant! no regeneration needed)')\n",
    "    print(f'  Table: {TABLE_NAME}')\n",
    "    print(f'  Time: <1 second (vs. 50+ minutes to regenerate)')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'✗ Could not load embeddings: {e}')\n",
    "    print(f'\\nMake sure foundation/02-rag-postgresql-persistent.ipynb has been run')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed80322",
   "metadata": {},
   "source": [
    "## Part 3: Retrieve Using Loaded Embeddings\n",
    "\n",
    "**Now you can perform RAG operations instantly using the pre-generated embeddings!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc51943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, top_n=3):\n",
    "    \"\"\"Retrieve most relevant chunks for a query using loaded embeddings.\"\"\"\n",
    "    # Generate query embedding (fast, only for this one query)\n",
    "    query_embedding = ollama.embed(model=EMBEDDING_MODEL, input=query)['embeddings'][0]\n",
    "    \n",
    "    # Search against all the pre-stored embeddings (instant)\n",
    "    return vector_db.similarity_search(query_embedding, top_n=top_n)\n",
    "\n",
    "# Test retrieval with loaded embeddings\n",
    "test_query = \"What is photosynthesis?\"\n",
    "print(f\"Query: '{test_query}'\\n\")\n",
    "\n",
    "results = retrieve(test_query, top_n=3)\n",
    "print(\"Retrieved chunks:\")\n",
    "for i, (chunk, score) in enumerate(results, 1):\n",
    "    title = chunk.split('\\n')[0]\n",
    "    preview = chunk[:200].replace('\\n', ' ') + '...'\n",
    "    print(f\"\\n  [{i}] Similarity: {score:.4f}\")\n",
    "    print(f\"      {title}\")\n",
    "    print(f\"      {preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fff7c2",
   "metadata": {},
   "source": [
    "## Part 4: The Load-or-Generate Pattern\n",
    "\n",
    "**Best Practice:** Check registry first, then decide to load or generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_generate(db_connection, embedding_model_alias, preserve_existing=True):\n",
    "    \"\"\"Smart pattern: Check registry, load if exists and compatible, generate if not.\n",
    "    \n",
    "    This is the KEY PATTERN for the advanced learning system:\n",
    "    - If embeddings exist and are compatible → load them (instant)\n",
    "    - If embeddings don't exist → prompt user to run foundation/02 first\n",
    "    - If different config needed → user chooses to regenerate\n",
    "    \n",
    "    Args:\n",
    "        db_connection: PostgreSQL connection\n",
    "        embedding_model_alias: Model to look for (e.g., 'bge_base_en_v1_5')\n",
    "        preserve_existing: If True, always load; if False, regenerate\n",
    "    \n",
    "    Returns:\n",
    "        PostgreSQLVectorDB instance ready for use\n",
    "    \"\"\"\n",
    "    # Step 1: Check if embeddings exist in registry\n",
    "    with db_connection.cursor() as cur:\n",
    "        cur.execute('''\n",
    "            SELECT id, dimension, embedding_count, metadata_json\n",
    "            FROM embedding_registry\n",
    "            WHERE model_alias = %s\n",
    "        ''', (embedding_model_alias,))\n",
    "        registry_entry = cur.fetchone()\n",
    "    \n",
    "    if registry_entry:\n",
    "        reg_id, dimension, embedding_count, metadata = registry_entry\n",
    "        \n",
    "        print(f\"✓ Found existing embeddings for '{embedding_model_alias}'\")\n",
    "        print(f\"  Embeddings: {embedding_count:,}\")\n",
    "        print(f\"  Dimension: {dimension}\")\n",
    "        \n",
    "        if preserve_existing:\n",
    "            print(f\"  Loading from PostgreSQL (no regeneration needed)\")\n",
    "            \n",
    "            # Return ready-to-use database\n",
    "            table_name = f'embeddings_{embedding_model_alias.replace(\".\", \"_\")}'\n",
    "            return PostgreSQLVectorDB({\n",
    "                'host': 'localhost',\n",
    "                'port': 5432,\n",
    "                'database': 'rag_db',\n",
    "                'user': 'postgres',\n",
    "                'password': 'postgres',\n",
    "            }, table_name)\n",
    "        else:\n",
    "            print(f\"  Would regenerate (preserve_existing=False)\")\n",
    "            print(f\"  NOT IMPLEMENTED - would need dataset + generation code\")\n",
    "    else:\n",
    "        print(f\"✗ No embeddings found for '{embedding_model_alias}'\")\n",
    "        print(f\"\\n  To create embeddings, run:\")\n",
    "        print(f\"  foundation/02-rag-postgresql-persistent.ipynb\")\n",
    "        return None\n",
    "\n",
    "# Example: Use the load-or-generate pattern\n",
    "print(\"=== Load-or-Generate Pattern ===\")\n",
    "loaded_db = load_or_generate(conn, 'bge_base_en_v1_5', preserve_existing=True)\n",
    "\n",
    "if loaded_db:\n",
    "    print(f\"\\n✓ Ready to use! {loaded_db.get_chunk_count():,} embeddings loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d742c25",
   "metadata": {},
   "source": [
    "## Part 5: Query Registry Metadata\n",
    "\n",
    "**Advanced:** Access detailed metadata about registered embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_metadata(db_connection, model_alias):\n",
    "    \"\"\"Fetch detailed metadata for a specific embedding model.\n",
    "    \n",
    "    Returns info like:\n",
    "    - Vector dimension (for compatibility checking)\n",
    "    - Chunk configuration (size, dataset source)\n",
    "    - When it was created/last used\n",
    "    - Flexible metadata (stored as JSON)\n",
    "    \"\"\"\n",
    "    with db_connection.cursor() as cur:\n",
    "        cur.execute('''\n",
    "            SELECT \n",
    "                dimension,\n",
    "                embedding_count,\n",
    "                chunk_source_dataset,\n",
    "                chunk_size_config,\n",
    "                created_at,\n",
    "                last_accessed,\n",
    "                metadata_json\n",
    "            FROM embedding_registry\n",
    "            WHERE model_alias = %s\n",
    "        ''', (model_alias,))\n",
    "        \n",
    "        result = cur.fetchone()\n",
    "        if result:\n",
    "            return {\n",
    "                'dimension': result[0],\n",
    "                'embedding_count': result[1],\n",
    "                'chunk_source_dataset': result[2],\n",
    "                'chunk_size_config': result[3],\n",
    "                'created_at': result[4],\n",
    "                'last_accessed': result[5],\n",
    "                'metadata_json': result[6],\n",
    "            }\n",
    "        return None\n",
    "\n",
    "# Retrieve metadata\n",
    "metadata = get_embedding_metadata(conn, 'bge_base_en_v1_5')\n",
    "\n",
    "if metadata:\n",
    "    print(\"=== Embedding Metadata ===\")\n",
    "    for key, value in metadata.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No metadata found for 'bge_base_en_v1_5'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c5044",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "1. **Registry Discovery**: Query `embedding_registry` to find cached embeddings\n",
    "2. **Instant Loading**: Load pre-generated embeddings in <1 second (vs. 50+ min to regenerate)\n",
    "3. **Load-or-Generate Pattern**: Check registry first, decide whether to load or regenerate\n",
    "4. **Metadata Access**: Use registry to understand embedding properties (dimension, source, timestamp)\n",
    "5. **Fast Experimentation**: Once embeddings are registered, you can experiment with techniques rapidly\n",
    "\n",
    "### Why This Matters:\n",
    "\n",
    "- **Without registry**: Each advanced technique experiment takes 50 minutes (embedding gen) + 5 minutes (technique) = 55 min\n",
    "- **With registry**: Each experiment takes <1 second (load) + 5 minutes (technique) = 5 min\n",
    "- **Result**: 10× faster iteration = more experiments, better learning!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **intermediate/04**: Learn how to compare multiple embedding models\n",
    "2. **advanced/05-10**: Use loaded embeddings to experiment with techniques\n",
    "3. **evaluation-lab**: Compare experiments and measure improvements\n",
    "\n",
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb09505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connections\n",
    "if vector_db:\n",
    "    vector_db.close()\n",
    "if conn:\n",
    "    conn.close()\n",
    "\n",
    "print(\"✓ Connections closed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
