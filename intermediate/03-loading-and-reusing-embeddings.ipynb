{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2250e25",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1bad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import psycopg2\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b682b",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ad4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL connection\n",
    "POSTGRES_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'rag_db',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres',\n",
    "}\n",
    "\n",
    "# Test embedding model\n",
    "EMBEDDING_MODEL = 'hf.co/CompendiumLabs/bge-base-en-v1.5-gguf'\n",
    "LANGUAGE_MODEL = 'hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f50c52",
   "metadata": {},
   "source": [
    "## Part 1: Discover Available Embeddings\n",
    "\n",
    "**What's in the registry?** Query the embedding_registry table to see what models and embeddings you have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_available_embeddings(db_connection):\n",
    "    \"\"\"Query embedding_registry to show available models with metadata.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: model_alias, model_name, dimension, embedding_count, etc.\n",
    "    \"\"\"\n",
    "    query = '''\n",
    "        SELECT \n",
    "            model_alias,\n",
    "            model_name,\n",
    "            dimension,\n",
    "            embedding_count,\n",
    "            chunk_source_dataset,\n",
    "            chunk_size_config,\n",
    "            created_at,\n",
    "            last_accessed\n",
    "        FROM embedding_registry\n",
    "        ORDER BY created_at DESC\n",
    "    '''\n",
    "    return pd.read_sql(query, db_connection)\n",
    "\n",
    "# Connect and discover embeddings\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=POSTGRES_CONFIG['host'],\n",
    "        port=POSTGRES_CONFIG['port'],\n",
    "        database=POSTGRES_CONFIG['database'],\n",
    "        user=POSTGRES_CONFIG['user'],\n",
    "        password=POSTGRES_CONFIG['password']\n",
    "    )\n",
    "    print(f'✓ Connected to PostgreSQL')\n",
    "    \n",
    "    # Query registry\n",
    "    available = list_available_embeddings(conn)\n",
    "    \n",
    "    if available.empty:\n",
    "        print(\"\\n⚠️  No embeddings found in registry!\")\n",
    "        print(\"\\nTo populate the registry, run: foundation/02-rag-postgresql-persistent.ipynb\")\n",
    "    else:\n",
    "        print(\"\\n=== Available Embeddings ===\")\n",
    "        print(available.to_string(index=False))\n",
    "        \n",
    "except psycopg2.OperationalError as e:\n",
    "    print(f'✗ Failed to connect: {e}')\n",
    "    print(\"Make sure PostgreSQL is running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1648e1",
   "metadata": {},
   "source": [
    "## Part 2: Load Embeddings from Registry\n",
    "\n",
    "**Now that you know what embeddings exist, load them!** This is instant (no regeneration needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostgreSQLVectorDB:\n",
    "    \"\"\"Helper to load embeddings from PostgreSQL without regeneration.\"\"\"\n",
    "    \n",
    "    def __init__(self, config, table_name):\n",
    "        self.config = config\n",
    "        self.table_name = table_name\n",
    "        self.conn = psycopg2.connect(\n",
    "            host=config['host'],\n",
    "            port=config['port'],\n",
    "            database=config['database'],\n",
    "            user=config['user'],\n",
    "            password=config['password']\n",
    "        )\n",
    "        print(f'✓ Connected to table: {table_name}')\n",
    "    \n",
    "    def get_chunk_count(self):\n",
    "        \"\"\"How many embeddings are stored?\"\"\"\n",
    "        with self.conn.cursor() as cur:\n",
    "            cur.execute(f'SELECT COUNT(*) FROM {self.table_name}')\n",
    "            return cur.fetchone()[0]\n",
    "    \n",
    "    def similarity_search(self, query_embedding, top_n=3):\n",
    "        \"\"\"Retrieve most similar chunks using pgvector.\"\"\"\n",
    "        with self.conn.cursor() as cur:\n",
    "            cur.execute(f'''\n",
    "                SELECT chunk_text, \n",
    "                       1 - (embedding <=> %s::vector) as similarity\n",
    "                FROM {self.table_name}\n",
    "                ORDER BY embedding <=> %s::vector\n",
    "                LIMIT %s\n",
    "            ''', (query_embedding, query_embedding, top_n))\n",
    "            \n",
    "            results = cur.fetchall()\n",
    "            return [(chunk, score) for chunk, score in results]\n",
    "    \n",
    "    def close(self):\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "\n",
    "# Load embeddings from registry (instant - no regeneration)\n",
    "EMBEDDING_MODEL_ALIAS = 'bge_base_en_v1_5'  # Match what foundation/02 registered\n",
    "TABLE_NAME = f'embeddings_{EMBEDDING_MODEL_ALIAS.replace(\".\", \"_\")}'\n",
    "\n",
    "try:\n",
    "    vector_db = PostgreSQLVectorDB(POSTGRES_CONFIG, TABLE_NAME)\n",
    "    count = vector_db.get_chunk_count()\n",
    "    \n",
    "    print(f'\\n✓ Loaded {count:,} embeddings from PostgreSQL (instant! no regeneration needed)')\n",
    "    print(f'  Table: {TABLE_NAME}')\n",
    "    print(f'  Time: <1 second (vs. 50+ minutes to regenerate)')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'✗ Could not load embeddings: {e}')\n",
    "    print(f'\\nMake sure foundation/02-rag-postgresql-persistent.ipynb has been run')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed80322",
   "metadata": {},
   "source": [
    "## Part 3: Retrieve Using Loaded Embeddings\n",
    "\n",
    "**Now you can perform RAG operations instantly using the pre-generated embeddings!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc51943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, top_n=3):\n",
    "    \"\"\"Retrieve most relevant chunks for a query using loaded embeddings.\"\"\"\n",
    "    # Generate query embedding (fast, only for this one query)\n",
    "    query_embedding = ollama.embed(model=EMBEDDING_MODEL, input=query)['embeddings'][0]\n",
    "    \n",
    "    # Search against all the pre-stored embeddings (instant)\n",
    "    return vector_db.similarity_search(query_embedding, top_n=top_n)\n",
    "\n",
    "# Test retrieval with loaded embeddings\n",
    "test_query = \"What is photosynthesis?\"\n",
    "print(f\"Query: '{test_query}'\\n\")\n",
    "\n",
    "results = retrieve(test_query, top_n=3)\n",
    "print(\"Retrieved chunks:\")\n",
    "for i, (chunk, score) in enumerate(results, 1):\n",
    "    title = chunk.split('\\n')[0]\n",
    "    preview = chunk[:200].replace('\\n', ' ') + '...'\n",
    "    print(f\"\\n  [{i}] Similarity: {score:.4f}\")\n",
    "    print(f\"      {title}\")\n",
    "    print(f\"      {preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fff7c2",
   "metadata": {},
   "source": "## Part 4: The Load-or-Generate Pattern\n\n**Best Practice:** Check registry first, then decide to load or generate.\n\nThis is the **core pattern** that enables fast iteration in advanced notebooks. Instead of regenerating embeddings every time you want to experiment with a new technique, you load them from the registry (instant) and focus on your technique implementation.\n\n**Time Savings Example:**\n- Without registry: 50 min (embedding generation) + 5 min (technique) = 55 min per experiment\n- With registry: <1 sec (load) + 5 min (technique) = 5 min per experiment\n- Result: 11× faster iteration!\n\n### Why This Pattern Matters\n\nWhen you move to advanced technique notebooks, you'll want to experiment with:\n- Different reranking strategies\n- Query expansion techniques\n- Hybrid search methods\n- Prompt engineering variations\n\nWith the load-or-generate pattern, each experiment takes 5 minutes instead of 55 minutes. This fundamentally changes how fast you can learn and iterate.\n\n### The Three Decisions\n\nWhen loading embeddings, the code makes three intelligent decisions:\n\n1. **Check Registry** - Are embeddings already stored for this model?\n2. **Display Time Savings** - Show user: \"Found X embeddings, loading in <1 sec vs 50 min\"\n3. **Interactive Choice** - Prompt: \"Load existing? (recommended) [y/n]\"\n\nYou can also programmatically control this with the `preserve_existing` parameter:\n- `None`: Prompt user interactively (default, safest for learning)\n- `True`: Always load (fastest, best for experiments)\n- `False`: Regenerate from scratch (useful for fresh runs)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691853d",
   "metadata": {},
   "outputs": [],
   "source": "def list_available_embeddings(db_connection):\n    \"\"\"Query embedding_registry to list all available embedding models.\n\n    Returns:\n        DataFrame with columns: model_alias, model_name, dimension,\n                               embedding_count, chunk_source_dataset,\n                               chunk_size_config, created_at\n    \"\"\"\n    try:\n        query = '''\n            SELECT\n                model_alias,\n                model_name,\n                dimension,\n                embedding_count,\n                chunk_source_dataset,\n                chunk_size_config,\n                created_at,\n                last_accessed\n            FROM embedding_registry\n            ORDER BY created_at DESC\n        '''\n        return pd.read_sql(query, db_connection)\n    except Exception as e:\n        print(f\"Note: Could not query registry: {e}\")\n        print(\"This is normal if foundation/00-setup-postgres-schema.ipynb hasn't been run yet.\")\n        return pd.DataFrame()\n\n\ndef get_embedding_metadata(db_connection, model_alias):\n    \"\"\"Fetch detailed metadata for a specific embedding model.\n\n    This helps verify compatibility and understand the configuration:\n    - Dimension: Must match for retrieval operations\n    - Chunk config: How the source data was split\n    - Created date: When this set was generated\n    - Metadata JSON: Custom notes, URLs, training info\n\n    Args:\n        db_connection: PostgreSQL connection\n        model_alias: The model alias (e.g., 'bge_base_en_v1_5')\n\n    Returns:\n        Dict with metadata, or None if not found\n    \"\"\"\n    try:\n        with db_connection.cursor() as cur:\n            cur.execute('''\n                SELECT\n                    dimension,\n                    embedding_count,\n                    chunk_source_dataset,\n                    chunk_size_config,\n                    created_at,\n                    last_accessed,\n                    metadata_json\n                FROM embedding_registry\n                WHERE model_alias = %s\n            ''', (model_alias,))\n\n            result = cur.fetchone()\n            if result:\n                return {\n                    'dimension': result[0],\n                    'embedding_count': result[1],\n                    'chunk_source_dataset': result[2],\n                    'chunk_size_config': result[3],\n                    'created_at': result[4],\n                    'last_accessed': result[5],\n                    'metadata_json': json.loads(result[6]) if result[6] else {}\n                }\n        return None\n    except Exception as e:\n        print(f\"Could not fetch metadata: {e}\")\n        return None\n\n\ndef load_or_generate(db_connection, embedding_model_alias, preserve_existing=None):\n    \"\"\"Smart pattern: Load embeddings from registry OR generate if not available.\n\n    This is the CORE PATTERN for the intermediate/advanced learning system.\n    It enables fast iteration by:\n    - Checking if embeddings already exist in PostgreSQL registry\n    - If they exist: Load instantly (<1 second, no regeneration)\n    - If not exist: Show guidance on how to generate them\n    - If user chooses to regenerate: Handle regeneration workflow\n\n    The preserve_existing flag controls the decision logic:\n    - None (default): Prompt user interactively (safest for learning)\n    - True: Always load existing embeddings (fastest, best for experiments)\n    - False: Always regenerate from scratch (useful for fresh runs)\n\n    Args:\n        db_connection: PostgreSQL connection object\n        embedding_model_alias: Model identifier (e.g., 'bge_base_en_v1_5')\n                              Should match what was used in foundation/02\n        preserve_existing: Decision flag for load vs regenerate\n                          - None: prompt user\n                          - True: always load\n                          - False: regenerate (requires foundation/02 to be re-run)\n\n    Returns:\n        PostgreSQLVectorDB instance ready for use, or None if no embeddings available\n\n    Raises:\n        ValueError: If user cancels the operation\n    \"\"\"\n\n    # === Step 1: Check if embeddings exist in registry ===\n    print(f\"Checking for embeddings: '{embedding_model_alias}'...\")\n\n    try:\n        with db_connection.cursor() as cur:\n            cur.execute('''\n                SELECT id, dimension, embedding_count, created_at, metadata_json\n                FROM embedding_registry\n                WHERE model_alias = %s\n            ''', (embedding_model_alias,))\n            registry_entry = cur.fetchone()\n    except Exception as e:\n        print(f\"Could not query registry: {e}\")\n        print(\"\\nMake sure foundation/00-setup-postgres-schema.ipynb has been run.\")\n        return None\n\n    # === Step 2: Case A - Embeddings exist ===\n    if registry_entry:\n        reg_id, dimension, embedding_count, created_at, metadata_json = registry_entry\n\n        # Display what we found\n        print(f\"\\n{'='*60}\")\n        print(f\"✓ FOUND EXISTING EMBEDDINGS\")\n        print(f\"{'='*60}\")\n        print(f\"Model:        {embedding_model_alias}\")\n        print(f\"Count:        {embedding_count:,} embeddings\")\n        print(f\"Dimension:    {dimension}\")\n        print(f\"Created:      {created_at}\")\n        print(f\"\\nTIME SAVINGS:\")\n        print(f\"  Loading embeddings: <1 second\")\n        print(f\"  Regenerating:       ~50+ minutes\")\n        print(f\"  ➜ You save 50+ minutes by loading!\")\n        print(f\"{'='*60}\\n\")\n\n        # === Step 3: Decide whether to load or regenerate ===\n        should_load = True\n\n        if preserve_existing is False:\n            # User explicitly wants to regenerate\n            print(\"⚠️  regeneration mode (preserve_existing=False)\")\n            print(\"Not implemented in this notebook.\")\n            print(\"To regenerate: run foundation/02-rag-postgresql-persistent.ipynb\")\n            return None\n\n        elif preserve_existing is None:\n            # Interactive prompt - safest for learning\n            print(\"What would you like to do?\\n\")\n            print(\"  [l] Load existing embeddings (recommended)\")\n            print(\"  [r] Regenerate from scratch\")\n            print(\"  [c] Cancel\\n\")\n\n            while True:\n                response = input(\"Choice [l/r/c]: \").lower().strip()\n\n                if response in ['l', 'load']:\n                    should_load = True\n                    print(\"\\n✓ Loading existing embeddings...\")\n                    break\n                elif response in ['r', 'regenerate']:\n                    print(\"\\nTo regenerate embeddings:\")\n                    print(\"  Run foundation/02-rag-postgresql-persistent.ipynb\")\n                    print(\"  Set PRESERVE_EXISTING_EMBEDDINGS = False\")\n                    return None\n                elif response in ['c', 'cancel']:\n                    raise ValueError(\"User cancelled operation\")\n                else:\n                    print('Invalid choice. Enter \"l\", \"r\", or \"c\"')\n\n        # === Step 4: Load embeddings if decided ===\n        if should_load:\n            try:\n                table_name = f'embeddings_{embedding_model_alias.replace(\".\", \"_\")}'\n\n                # Create PostgreSQL connection for the vector DB\n                db_instance = PostgreSQLVectorDB(\n                    config=POSTGRES_CONFIG,\n                    table_name=table_name,\n                    preserve_existing=True  # Already exists, don't recreate\n                )\n\n                count = db_instance.get_chunk_count()\n                print(f\"\\n{'='*60}\")\n                print(f\"✓ LOADED SUCCESSFULLY\")\n                print(f\"{'='*60}\")\n                print(f\"Embeddings loaded: {count:,}\")\n                print(f\"Table:            {table_name}\")\n                print(f\"Status:           Ready for retrieval operations\")\n                print(f\"{'='*60}\\n\")\n\n                return db_instance\n\n            except Exception as e:\n                print(f\"\\n✗ Error loading embeddings: {e}\")\n                print(f\"\\nTroubleshooting:\")\n                print(f\"  1. Verify PostgreSQL is running\")\n                print(f\"  2. Check POSTGRES_CONFIG settings (above)\")\n                print(f\"  3. Run foundation/02 to generate embeddings first\")\n                return None\n\n    # === Step 5: Case B - No embeddings found ===\n    else:\n        print(f\"\\n{'='*60}\")\n        print(f\"✗ NO EMBEDDINGS FOUND\")\n        print(f\"{'='*60}\")\n        print(f\"Model:  {embedding_model_alias}\")\n        print(f\"\\nTo create embeddings, run:\")\n        print(f\"  foundation/02-rag-postgresql-persistent.ipynb\")\n        print(f\"\\nThen come back here and re-run this cell.\")\n        print(f\"{'='*60}\\n\")\n\n        return None\n\n\n# === DEMONSTRATION: Use the load-or-generate pattern ===\n\nprint(\"Demonstrating load-or-generate pattern...\\n\")\n\n# First, list what embeddings are available in the registry\nprint(\"Step 1: Checking registry for available embeddings...\\n\")\navailable = list_available_embeddings(conn)\n\nif available.empty:\n    print(\"⚠️  No embeddings found in registry yet.\")\n    print(\"Run foundation/02-rag-postgresql-persistent.ipynb first.\\n\")\nelse:\n    print(\"Available embeddings:\")\n    print(available.to_string(index=False))\n    print()\n\n# Now use load-or-generate to intelligently load or handle missing embeddings\nprint(\"Step 2: Using load-or-generate pattern...\\n\")\nEMBEDDING_MODEL_ALIAS = 'bge_base_en_v1.5'  # Match the alias from foundation/02\n\nloaded_db = load_or_generate(\n    db_connection=conn,\n    embedding_model_alias=EMBEDDING_MODEL_ALIAS,\n    preserve_existing=True  # For this notebook, always load if available\n)\n\nif loaded_db:\n    print(f\"\\n✓ Success! You can now use the embeddings.\")\n    print(f\"Total embeddings available: {loaded_db.get_chunk_count():,}\\n\")\nelse:\n    print(f\"\\n⚠️  Could not load embeddings. See instructions above.\")"
  },
  {
   "cell_type": "markdown",
   "id": "1d742c25",
   "metadata": {},
   "source": [
    "## Part 5: Query Registry Metadata\n",
    "\n",
    "**Advanced:** Access detailed metadata about registered embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3z5ip55yq9p",
   "source": "## Part 4b: Understanding the Load-or-Generate Pattern\n\nThe three utility functions work together to implement a smart, user-friendly pattern:\n\n### Function 1: `list_available_embeddings(db_connection)`\nShows all embedding models in the registry. Run this to see what you have available.\n\n**Returns:** DataFrame with all registered models and their metadata\n**Use case:** \"What embedding models do I have available for reuse?\"\n\n### Function 2: `get_embedding_metadata(db_connection, model_alias)`\nGets detailed information about one specific embedding model.\n\n**Returns:** Dict with dimension, count, chunk config, created date, custom metadata\n**Use case:** \"Is this embedding model compatible? How was it generated?\"\n\n### Function 3: `load_or_generate(db_connection, embedding_model_alias, preserve_existing=None)`\nThe main pattern - checks registry and intelligently decides whether to load or generate.\n\n**Key features:**\n- Checks if embeddings exist in registry\n- Shows time savings message if found\n- Prompts user interactively (or uses preserve_existing flag)\n- Handles errors gracefully with troubleshooting tips\n- Returns PostgreSQLVectorDB ready for retrieval\n\n**Arguments:**\n- `db_connection`: Your PostgreSQL connection\n- `embedding_model_alias`: Model to look for (e.g., 'bge_base_en_v1.5')\n- `preserve_existing`: None=prompt, True=always load, False=regenerate\n\n**Returns:** PostgreSQLVectorDB instance, or None if not found\n\n### Decision Flow\n\n```\nload_or_generate() called\n    ↓\nCheck registry for embeddings\n    ↓\n    ├─ Embeddings found:\n    │   ├─ preserve_existing=None? → Ask user\n    │   ├─ preserve_existing=True?  → Load automatically\n    │   └─ preserve_existing=False? → Tell user how to regenerate\n    │\n    └─ No embeddings found:\n        └─ Show error with instructions\n```\n\n### Example: Using in Your Code\n\n```python\n# In any intermediate or advanced notebook:\n\n# Step 1: See what embeddings you have\navailable = list_available_embeddings(conn)\nprint(available)\n\n# Step 2: Check if specific model is available\nmetadata = get_embedding_metadata(conn, 'bge_base_en_v1.5')\nif metadata:\n    print(f\"Found {metadata['embedding_count']} embeddings\")\n    print(f\"Dimension: {metadata['dimension']}\")\n\n# Step 3: Load with user prompt (interactive)\ndb = load_or_generate(conn, 'bge_base_en_v1.5', preserve_existing=None)\n\n# Step 4: Or load automatically (non-interactive, for scripts)\ndb = load_or_generate(conn, 'bge_base_en_v1.5', preserve_existing=True)\n\n# Step 5: Use for retrieval\nif db:\n    results = db.similarity_search(query_embedding, top_n=3)\n```\n\n### Why Inline Functions Matter\n\nThese functions are defined inline in this notebook (not in a separate module) because:\n\n1. **Pedagogical clarity** - You see the full implementation as you learn\n2. **Copy-paste pattern** - You can easily copy them into your own notebooks\n3. **Low friction** - No import statements or dependency setup needed\n4. **Educational value** - Understanding the code matters more than packaging efficiency\n\nIn a production system, these would be in a shared utility module. But for learning, inline is better!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_metadata(db_connection, model_alias):\n",
    "    \"\"\"Fetch detailed metadata for a specific embedding model.\n",
    "    \n",
    "    Returns info like:\n",
    "    - Vector dimension (for compatibility checking)\n",
    "    - Chunk configuration (size, dataset source)\n",
    "    - When it was created/last used\n",
    "    - Flexible metadata (stored as JSON)\n",
    "    \"\"\"\n",
    "    with db_connection.cursor() as cur:\n",
    "        cur.execute('''\n",
    "            SELECT \n",
    "                dimension,\n",
    "                embedding_count,\n",
    "                chunk_source_dataset,\n",
    "                chunk_size_config,\n",
    "                created_at,\n",
    "                last_accessed,\n",
    "                metadata_json\n",
    "            FROM embedding_registry\n",
    "            WHERE model_alias = %s\n",
    "        ''', (model_alias,))\n",
    "        \n",
    "        result = cur.fetchone()\n",
    "        if result:\n",
    "            return {\n",
    "                'dimension': result[0],\n",
    "                'embedding_count': result[1],\n",
    "                'chunk_source_dataset': result[2],\n",
    "                'chunk_size_config': result[3],\n",
    "                'created_at': result[4],\n",
    "                'last_accessed': result[5],\n",
    "                'metadata_json': result[6],\n",
    "            }\n",
    "        return None\n",
    "\n",
    "# Retrieve metadata\n",
    "metadata = get_embedding_metadata(conn, 'bge_base_en_v1_5')\n",
    "\n",
    "if metadata:\n",
    "    print(\"=== Embedding Metadata ===\")\n",
    "    for key, value in metadata.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No metadata found for 'bge_base_en_v1_5'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c5044",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "1. **Registry Discovery**: Query `embedding_registry` to find cached embeddings\n",
    "2. **Instant Loading**: Load pre-generated embeddings in <1 second (vs. 50+ min to regenerate)\n",
    "3. **Load-or-Generate Pattern**: Check registry first, decide whether to load or regenerate\n",
    "4. **Metadata Access**: Use registry to understand embedding properties (dimension, source, timestamp)\n",
    "5. **Fast Experimentation**: Once embeddings are registered, you can experiment with techniques rapidly\n",
    "\n",
    "### Why This Matters:\n",
    "\n",
    "- **Without registry**: Each advanced technique experiment takes 50 minutes (embedding gen) + 5 minutes (technique) = 55 min\n",
    "- **With registry**: Each experiment takes <1 second (load) + 5 minutes (technique) = 5 min\n",
    "- **Result**: 10× faster iteration = more experiments, better learning!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **intermediate/04**: Learn how to compare multiple embedding models\n",
    "2. **advanced/05-10**: Use loaded embeddings to experiment with techniques\n",
    "3. **evaluation-lab**: Compare experiments and measure improvements\n",
    "\n",
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb09505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connections\n",
    "if vector_db:\n",
    "    vector_db.close()\n",
    "if conn:\n",
    "    conn.close()\n",
    "\n",
    "print(\"✓ Connections closed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}