{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9efe2f3c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ce697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "POSTGRES_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'rag_db',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres',\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df21d3",
   "metadata": {},
   "source": [
    "## Part 1: List Available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8194cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=POSTGRES_CONFIG['host'],\n",
    "    port=POSTGRES_CONFIG['port'],\n",
    "    database=POSTGRES_CONFIG['database'],\n",
    "    user=POSTGRES_CONFIG['user'],\n",
    "    password=POSTGRES_CONFIG['password']\n",
    ")\n",
    "\n",
    "query = '''\n",
    "    SELECT model_alias, model_name, dimension, embedding_count, created_at\n",
    "    FROM embedding_registry\n",
    "    ORDER BY created_at DESC\n",
    "'''\n",
    "available = pd.read_sql(query, conn)\n",
    "print(\"=== Available Embedding Models ===\")\n",
    "print(available.to_string(index=False))\n",
    "print(f\"\\nTotal: {len(available)} model(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed4b73",
   "metadata": {},
   "source": [
    "## Part 2: Compare Retrieval Quality\n",
    "\n",
    "This section demonstrates how to compare retrieval results across different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostgreSQLVectorDB:\n",
    "    def __init__(self, config, table_name):\n",
    "        self.config = config\n",
    "        self.table_name = table_name\n",
    "        self.conn = psycopg2.connect(\n",
    "            host=config['host'],\n",
    "            port=config['port'],\n",
    "            database=config['database'],\n",
    "            user=config['user'],\n",
    "            password=config['password']\n",
    "        )\n",
    "    \n",
    "    def get_chunk_count(self):\n",
    "        with self.conn.cursor() as cur:\n",
    "            cur.execute(f'SELECT COUNT(*) FROM {self.table_name}')\n",
    "            return cur.fetchone()[0]\n",
    "    \n",
    "    def similarity_search(self, query_embedding, top_n=5):\n",
    "        with self.conn.cursor() as cur:\n",
    "            cur.execute(f'''\n",
    "                SELECT chunk_text, 1 - (embedding <=> %s::vector) as similarity\n",
    "                FROM {self.table_name}\n",
    "                ORDER BY embedding <=> %s::vector\n",
    "                LIMIT %s\n",
    "            ''', (query_embedding, query_embedding, top_n))\n",
    "            return [(chunk, score) for chunk, score in cur.fetchall()]\n",
    "    \n",
    "    def close(self):\n",
    "        if self.conn:\n",
    "            self.conn.close()\n",
    "\n",
    "print(\"Vector DB class loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d73e62",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "### Embedding Model Comparison\n",
    "\n",
    "To effectively compare embedding models:\n",
    "\n",
    "1. **Generate embeddings with each model** using foundation/02\n",
    "2. **Store in separate tables** (embedding_bge_base, embedding_bge_small, etc.)\n",
    "3. **Query with the same test set** to compare retrieval quality\n",
    "4. **Measure metrics**: Precision@K, Recall, MRR, response time\n",
    "\n",
    "### Common Models\n",
    "\n",
    "- **BGE-Base (768D)**: Balanced quality/speed (current default)\n",
    "- **BGE-Small (384D)**: Faster, lower quality\n",
    "- **UAE-Large (768D)**: Higher quality, similar speed\n",
    "\n",
    "### How to Add a Second Model\n",
    "\n",
    "1. Install: `ollama pull hf.co/CompendiumLabs/bge-small-en-v1.5-gguf`\n",
    "2. Edit foundation/02: Change `EMBEDDING_MODEL = 'hf.co/CompendiumLabs/bge-small-en-v1.5-gguf'`\n",
    "3. Run foundation/02 again (creates new embeddings_bge_small table)\n",
    "4. Come back here and compare!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf511616",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff202e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "print(\"âœ“ Connections closed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
